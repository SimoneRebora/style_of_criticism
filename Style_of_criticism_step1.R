###The following code analyzes texts in the "corpus" folder based on the dictionaries in the "lexicons" folder (note: the lexicons are generated by the "Extend_lexicons.py" Python script)
###It also prepares the texts for the (external) analysis with LIWC
###The corpus should be divided in three subgroups, each one saved in an independent .txt file
###(e.g. "TextGroup1.txt", "TextGroup2.txt", "TextGroup3.txt")

library(methods)	# to avoid error with nohup
library(stylo)      # for the stylometric analysis
library(stringr)    # to manipulate strings

###Here you should define the most important variable
###i.e. the length of the samples into which you would like to split your corpus

split_length <- 500

###Other variables: names of the lexicons and the output file 

Knoop_lexicon_file <- "lexicons/Lexicon_Knoop_ext.csv"
mental_imagery_lexicon_file <- "lexicons/Lexicon_Mental_Imagery_ext.csv"
dizionario_critica_file <- "lexicons/Dizionario_critica.csv"
output_file <- "Results_step1.RData"

##################
######Main functions definition
#########

##base function (split based on simple spaces and preserving all characters: all split words are put back in line)
make_lexicon_simple <- function(text_corpus, text_corpus_title, length_limit = 5000){
  print("paste corpus")
  text_corpus <- paste(text_corpus, collapse = " ")
  print("split with space")
  text_corpus <- unlist(strsplit(text_corpus, " "))
  print("split in groups")
  text_corpus <- split(text_corpus, ceiling(seq_along(text_corpus)/length_limit))
  text_corpus <- text_corpus[-length(text_corpus)]
  print("back into one string")
  for(i in 1:length(text_corpus)){
    text_corpus[[i]] <- paste(text_corpus[[i]], collapse = " ")
  }
  names(text_corpus) <- paste(text_corpus_title, 1:length(text_corpus), sep = "_")
  print("Simple lexicon done")
  return(text_corpus)
}

###prepare Stylo corpus (classic approach)
make_lexicon_stylo_classic <- function(text_corpus, text_corpus_title, length_limit = 5000){
  text_corpus <- make_lexicon_simple(text_corpus, text_corpus_title, split_length)
  print("Prepare stylo corpus")
  for(i in 1:length(text_corpus)){
    text_corpus[[i]] <- stylo::txt.to.words.ext(text_corpus[[i]], language = "Italian")
  }
  print("Stylo corpus done")
  return(text_corpus)
}

###advanced function (based on Stylo's tokenization)
make_lexicon_stylo_advanced <- function(text_corpus, text_corpus_title, length_limit = 5000){
  text_corpus <- make_lexicon_simple(text_corpus, text_corpus_title, split_length)
  print("Prepare stylo lexicon")
  for(i in 1:length(text_corpus)){
    text_corpus[[i]] <- stylo::txt.to.words.ext(text_corpus[[i]], language = "Italian")
    text_corpus[[i]] <- sort(table(text_corpus[[i]]), decreasing = T)
  }
  print("Stylo lexicon done")
  return(text_corpus)
}

##alternative function (keeping words in line - after Stylo's processing)
make_lexicon_full <- function(text_corpus, text_corpus_title, length_limit = 5000, corpus_limit = 600){
  text_corpus <- make_lexicon_simple(text_corpus, text_corpus_title, split_length)
  print("Prepare stylo-processed corpus")
  for(i in 1:length(text_corpus)){
    text_corpus[[i]] <- stylo::txt.to.words.ext(text_corpus[[i]], language = "Italian")
    text_corpus[[i]] <- paste(text_corpus[[i]], collapse = " ")
    text_corpus[[i]] <- paste(" ", text_corpus[[i]], " ", sep = "")
  }
  print("Stylo-processed corpus done")
  return(text_corpus)
}

##############
####First phase (Knoop and Imagery)
###########

###prepare sub-corpora

corpora_files <- list.files("corpus", full.names = T)

corpus_1 <- readLines(corpora_files[1])
corpus_1 <- make_lexicon_stylo_advanced(corpus_1, "corpus1", length_limit = split_length)

corpus_2 <- readLines(corpora_files[2])
corpus_2 <- make_lexicon_stylo_advanced(corpus_2, "corpus2", length_limit = split_length)

corpus_3 <- readLines(corpora_files[3])
corpus_3 <- make_lexicon_stylo_advanced(corpus_3, "corpus3", length_limit = split_length)

###prepare full corpus for analysis

full_corpus <- c(corpus_1, corpus_2, corpus_3)

evaluation_results <- data.frame(stylometry=character(length(full_corpus)), stringsAsFactors = F)
rownames(evaluation_results) <- names(full_corpus)

###Knoop analysis

lessico <- read.csv(Knoop_lexicon_file, stringsAsFactors = F)
lessico <- tolower(lessico$word)

Knoop_score <- numeric()
for(i in 1:length(full_corpus)){
  Knoop_score[i] <- sum(full_corpus[[i]][which(names(full_corpus[[i]]) %in% lessico)])
}

evaluation_results <- cbind(evaluation_results, Knoop_score)

###Mental Imagery

lessico <- read.csv(mental_imagery_lexicon_file, stringsAsFactors = F)
lessico <- tolower(lessico$word)

Imagery_score <- numeric()
for(i in 1:length(full_corpus)){
  Imagery_score[i] <- sum(full_corpus[[i]][which(names(full_corpus[[i]]) %in% lessico)])
}

evaluation_results <- cbind(evaluation_results, Imagery_score)

##############
####Second phase (dizionario della critica)
###########

###prepare sub-corpora

corpora_files <- list.files("corpus", full.names = T)

corpus_1 <- readLines(corpora_files[1])
corpus_1 <- make_lexicon_full(corpus_1, "corpus1", length_limit = split_length)

corpus_2 <- readLines(corpora_files[2])
corpus_2 <- make_lexicon_full(corpus_2, "corpus2", length_limit = split_length)

corpus_3 <- readLines(corpora_files[3])
corpus_3 <- make_lexicon_full(corpus_3, "corpus3", length_limit = split_length)

###prepare full corpus for analysis

full_corpus <- c(corpus_1, corpus_2, corpus_3)

##Lessico della critica analysis

lessico_critica <- read.csv(dizionario_critica_file, stringsAsFactors = F)
lessico_critica <- tolower(lessico_critica$ITALIAN)
lessico_critica <- paste(" ", lessico_critica, " ", sep = "")

LessicoCritica_score <- rep(0, length(full_corpus))

for(word in lessico_critica){
  print(word)
  LessicoCritica_score <- LessicoCritica_score + str_count(full_corpus, word)
}

evaluation_results <- cbind(evaluation_results, LessicoCritica_score)

##############
####Third phase (stylometric analysis)
###########

###prepare sub-corpora

corpora_files <- list.files("corpus", full.names = T)

corpus_1 <- readLines(corpora_files[1])
corpus_1 <- make_lexicon_full(corpus_1, "corpus1", length_limit = split_length)

corpus_2 <- readLines(corpora_files[2])
corpus_2 <- make_lexicon_full(corpus_2, "corpus2", length_limit = split_length)

corpus_3 <- readLines(corpora_files[3])
corpus_3 <- make_lexicon_full(corpus_3, "corpus3", length_limit = split_length)

###prepare full corpus for analysis

full_corpus <- c(corpus_1, corpus_2, corpus_3)

##Stylometric analysis

results_stylo <- stylo(gui = FALSE, corpus.lang="Italian", analysis.type="CA", mfw.min=2000, mfw.max=2000, mfw.incr=0, distance.measure="dist.wurzburg", write.pdf.file = FALSE, parsed.corpus = full_corpus, write.png.file = F)

for(i in 1:length(results_stylo$distance.table[1,])){
  evaluation_results$stylometry[i] <- paste(unlist(strsplit(names(sort(results_stylo$distance.table[i,]))[2:4], "_"))[c(1,3,5)], collapse = "_")
}

evaluation_results$stylometry <- as.factor(evaluation_results$stylometry)

##############
####Fourth phase (prepare for LIWC analysis)
###########

###prepare sub-corpora

corpora_files <- list.files("corpus", full.names = T)

corpus_1 <- readLines(corpora_files[1])
corpus_1 <- make_lexicon_simple(corpus_1, "corpus1", length_limit = split_length)

corpus_2 <- readLines(corpora_files[2])
corpus_2 <- make_lexicon_simple(corpus_2, "corpus2", length_limit = split_length)

corpus_3 <- readLines(corpora_files[3])
corpus_3 <- make_lexicon_simple(corpus_3, "corpus3", length_limit = split_length)

###prepare full corpus for analysis

full_corpus <- c(corpus_1, corpus_2, corpus_3)

###Save all in a new directory "LIWCCorpus"

dir.create(file.path("LIWCCorpus"))

for(i in 1:length(full_corpus))
  cat(full_corpus[[i]], sep = "", file = paste("LIWCCorpus/", names(full_corpus)[i], ".txt", sep = ""))

save(evaluation_results, file = output_file)

cat("Preparation complete.\nNow analyze the files in the LIWCCorpus folder with the LIWC software.\nPlease save the results in a file called \"LIWC_results.csv\"")